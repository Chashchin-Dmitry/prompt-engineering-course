[
  {
    "article_id": "91e1475718cbd3d6",
    "article_title": "üí° What is Prompt Engineering ?:: RAG, CoT, ReAct & DSP Explained",
    "article_url": "https://medium.com/@tahirbalarabe2/what-is-prompt-engineering-rag-cot-react-dsp-explained-0aa0a9bd0a90",
    "module": "02-core-techniques",
    "tags": [
      "prompt-engineering",
      "chain-of-thought",
      "RAG"
    ],
    "chunk_index": 0,
    "total_chunks": 5,
    "text": "üí° What is Prompt Engineering ?:: RAG, CoT, ReAct & DSP Explained Tahir 7 min read ¬∑ Jan 31, 2025 -- If you‚Äôve spent any time on LinkedIn lately, you‚Äôve probably seen job postings for ‚Äúprompt engineers.‚Äù A few years ago, this job didn‚Äôt exist. Now, companies are scrambling to hire people who know how to ask AI the right questions. The reason is simple: large language models (LLMs) don‚Äôt just think on their own. They generate text based on probabilities, and if you don‚Äôt guide them well, they‚Äôll make things up. AI researchers call these mistakes ‚Äúhallucinations,‚Äù but it‚Äôs really just bad prompting. The solution? Better prompts. There are four main techniques for doing this: Retrieval-Augmented Generation (RAG), Chain of Thought (CoT), ReAct, and Directional Stimulus Prompting (DSP). Each solves a different problem, and when used together, they make AI far more reliable. Retrieval-Augmented Generation (RAG) Most AI models are trained on internet data. This means they don‚Äôt know anything about your company‚Äôs internal policies or the latest financial reports. If you ask an LLM about your revenue last year, it won‚Äôt know. It will guess. RAG fixes this. Instead of relying purely on the model‚Äôs training data, you first retrieve relevant information from a trusted source ‚Äî like a company database or a document repository ‚Äî and then feed it into the model. Now, when you ask about revenue, the model isn‚Äôt pulling numbers from the air. It‚Äôs using real data. This works best when paired with vector databases, which store text in a format that AI can quickly search. If you‚Äôve ever used a chatbot that seems to ‚Äúknow‚Äù your company‚Äôs policies, it‚Äôs probably using RAG. Chain of Thought (CoT) Most people assume AI works like a calculator ‚Äî give it an input, and it instantly spits out the right answer. But LLMs don‚Äôt work that way. They generate text one token at a time, based on what‚Äôs most likely to come next. This can cause problems when answering complex questions. If you ask, ‚ÄúWhat was our total revenue for 2022?‚Äù the model might throw out a number with no reasoning. Chain of Thought prompting forces the model to show its work. Instead of asking for a single number, you break the problem into parts: What was the revenue from software sales? What was the revenue from consulting? What was the revenue from hardware? Now, sum them up. By structuring the question this way, you help the model arrive at a more reliable answer. And even if it‚Äôs wrong, you can see where it went wrong. ReAct RAG brings in external data. Chain of Thought forces reasoning. But what if the model needs information that isn‚Äôt in its training data or your private knowledge base? This is where ReAct comes in. It lets AI decide when to retrieve more data before answering. Imagine you ask, ‚ÄúWhat were our revenues in 2010 and 2022?‚Äù The model might find 2022‚Äôs numbers in your database but not 2010‚Äôs. Instead of"
  },
  {
    "article_id": "91e1475718cbd3d6",
    "article_title": "üí° What is Prompt Engineering ?:: RAG, CoT, ReAct & DSP Explained",
    "article_url": "https://medium.com/@tahirbalarabe2/what-is-prompt-engineering-rag-cot-react-dsp-explained-0aa0a9bd0a90",
    "module": "02-core-techniques",
    "tags": [
      "prompt-engineering",
      "chain-of-thought",
      "RAG"
    ],
    "chunk_index": 1,
    "total_chunks": 5,
    "text": "its training data or your private knowledge base? This is where ReAct comes in. It lets AI decide when to retrieve more data before answering. Imagine you ask, ‚ÄúWhat were our revenues in 2010 and 2022?‚Äù The model might find 2022‚Äôs numbers in your database but not 2010‚Äôs. Instead of making up a number, it can recognize the gap, search an external source, and then combine both numbers before responding. ReAct is useful when models need to cross-check information from multiple places. It prevents AI from answering when it shouldn‚Äôt and makes sure responses are built on actual data. Directional Stimulus Prompting (DSP) Sometimes you don‚Äôt want a general answer. You want AI to focus on specific details. That‚Äôs where DSP comes in. Suppose you ask, ‚ÄúWhat were our total earnings last year?‚Äù The model might give you one number. But if you want more precision, you can direct it: ‚ÄúFocus on software and consulting revenue.‚Äù ‚ÄúIgnore international sales.‚Äù ‚ÄúSummarize in three bullet points.‚Äù This kind of prompting works like giving hints in a guessing game. Instead of asking for a broad answer, you nudge the model toward what you actually need. It‚Äôs simple but surprisingly effective. Combining These Techniques The real power of prompt engineering comes from combining these techniques. For example, you might start with RAG to ground the model in your domain knowledge, then use COT to break down a complex problem, and finally apply DSP to extract specific details. Each technique has its strengths, and using them together can produce results that are far more accurate and insightful than any single approach. Each of these techniques solves a different problem: RAG makes sure AI has access to the right data. Chain of Thought forces reasoning. ReAct lets AI search for missing info. DSP helps you steer the response. Used together, they make AI much more reliable. Instead of answering based on random training data, the model retrieves real facts, reasons through them, pulls in extra information if needed, and presents the result in the right format. This is what good prompt engineering looks like. It‚Äôs not about tricking AI into giving better answers. It‚Äôs about structuring your questions so the model works the way you want. If you want AI to be useful, don‚Äôt just ask it questions. Guide it. Why This Matters Prompt engineering isn‚Äôt just a technical skill; it‚Äôs a way of thinking. It forces you to clarify your questions and understand the limitations of the tools you‚Äôre using. And like any form of communication, it‚Äôs iterative. You rarely get the perfect response on the first try. You refine your prompts, test different approaches, and learn from the results. This is why prompt engineering is becoming such a sought-after skill. As LLMs become more integrated into our workflows, the ability to communicate effectively with them will be as important as knowing how to use a spreadsheet or write code. It‚Äôs not just about making the models work ‚Äî it‚Äôs about making them work for"
  },
  {
    "article_id": "91e1475718cbd3d6",
    "article_title": "üí° What is Prompt Engineering ?:: RAG, CoT, ReAct & DSP Explained",
    "article_url": "https://medium.com/@tahirbalarabe2/what-is-prompt-engineering-rag-cot-react-dsp-explained-0aa0a9bd0a90",
    "module": "02-core-techniques",
    "tags": [
      "prompt-engineering",
      "chain-of-thought",
      "RAG"
    ],
    "chunk_index": 2,
    "total_chunks": 5,
    "text": "is becoming such a sought-after skill. As LLMs become more integrated into our workflows, the ability to communicate effectively with them will be as important as knowing how to use a spreadsheet or write code. It‚Äôs not just about making the models work ‚Äî it‚Äôs about making them work for you . So if you‚Äôre curious about this field, start experimenting. Play around with different prompts. Try combining techniques. And remember: the best way to learn prompt engineering is by doing it. The more you practice, the better you‚Äôll get. And who knows? You might just find yourself becoming one of those in-demand prompt engineers. Further Reading:: ü§ñChatGPT for Vulnerability Detection by Tahir Balarabe What are AI Agents? Stable Diffusion Deepfakes: Creation and Detection The Difference Between AI Assistants and AI Agents (And Why It Matters) üöÄDeepSeek R1 Explained: Chain of Thought, Reinforcement Learning, and Model Distillation ü§îWhat is AI Inferencing? üí°Prompt Tuning: A New Approach to Large Language Model Specialization üí°Retrieval-Augmented Generation(RAG) for Accurate LLMs FAQ on Prompt Engineering Techniques What is prompt engineering and why is it important? Prompt engineering is the practice of designing effective questions and instructions (prompts) to elicit desired responses from large language models (LLMs). It‚Äôs crucial because LLMs are trained on vast datasets and can produce inaccurate or nonsensical outputs (hallucinations) if not guided properly. By carefully crafting prompts, we can minimize these issues and leverage the LLMs capabilities effectively for specific tasks. What is Retrieval Augmented Generation (RAG) and how does it improve LLM responses? RAG enhances LLMs by incorporating domain-specific knowledge into the process. LLMs are not inherently aware of private or niche knowledge bases. RAG works by first retrieving relevant information from your specific knowledge source (e.g., a company database) using a retrieval component. Then this retrieved context is combined with your question to provide LLM a foundation for its answer. This allows the model to provide answers based on your domain specific data, improving accuracy and relevance over using the LLM‚Äôs generic training. How does the Chain-of-Thought (COT) prompting technique work and how does it differ from RAG? COT is a method that guides the LLM through a problem by breaking it down into multiple steps. Rather than asking a complex question directly, you prompt the model to reason through each part of the question, and then combine these into a final result. For example, instead of asking for the total earnings of a company, you might ask for earnings by software, hardware, and consulting before adding them together. This encourages explainability and often leads to more accurate results. COT is a technique that builds on the base accuracy of results (such as ones achieved through the RAG technique) by providing a framework for better question phrasing, whereas RAG is a method to improve the model‚Äôs content awareness. What is the ReAct prompting technique, and how does it differ from both RAG and COT? ReAct combines reasoning (similar to COT) with the ability to take actions by accessing external"
  },
  {
    "article_id": "91e1475718cbd3d6",
    "article_title": "üí° What is Prompt Engineering ?:: RAG, CoT, ReAct & DSP Explained",
    "article_url": "https://medium.com/@tahirbalarabe2/what-is-prompt-engineering-rag-cot-react-dsp-explained-0aa0a9bd0a90",
    "module": "02-core-techniques",
    "tags": [
      "prompt-engineering",
      "chain-of-thought",
      "RAG"
    ],
    "chunk_index": 3,
    "total_chunks": 5,
    "text": "by providing a framework for better question phrasing, whereas RAG is a method to improve the model‚Äôs content awareness. What is the ReAct prompting technique, and how does it differ from both RAG and COT? ReAct combines reasoning (similar to COT) with the ability to take actions by accessing external resources. If the answer cannot be found entirely in the internal or domain-specific knowledge base, ReAct prompts the LLM to search for information in external public sources as well. This means the model can gather missing data from various sources to complete the task. For instance, in the example of retrieving financial data for two different years, ReAct is able to retrieve one from a private database and then supplement it with one from a public source. ReAct uses a 3 step process of ‚Äúthought,‚Äù ‚Äúaction,‚Äù and ‚Äúobservation‚Äù to accomplish this. Can you explain Directional Stimulus Prompting (DSP) and its usefulness? DSP is a technique to guide the model towards very specific information from within a result. When asking a question, you include specific keywords or ‚Äúhints‚Äù to encourage the model to extract particular data from a larger result. For example, you may ask, ‚ÄúWhat is the company‚Äôs annual earnings, specifically for the software and consulting departments?‚Äù It‚Äôs a simple yet effective method for extracting specific pieces of information. How are these different prompt engineering techniques combined for optimal results? A common approach is to start with RAG to ground the LLM in your domain specific knowledge. You can then layer in other techniques, such as combining Chain-of-Thought with RAG, or even ReAct with RAG. For very specific data extraction, the combination of RAG and DSP can be highly effective. The goal is to leverage the cumulative effect of these techniques to refine the LLM‚Äôs response. What are ‚Äúhallucinations‚Äù in the context of large language models, and how do these techniques address them? ‚ÄúHallucinations‚Äù in LLMs refer to inaccurate or false outputs generated by the model. These occur when the model relies too heavily on its pre-training data or makes up information because it lacks awareness of a context. Techniques like RAG address this by grounding responses in domain-specific knowledge, while methods like COT and ReAct encourage logical reasoning by the LLM and use of external sources. DSP also plays a role by guiding the model to more targeted answers. What are the ‚Äúfew-shot‚Äù prompting techniques that were discussed in the source? Both Chain-of-Thought (COT) and ReAct are considered few-shot prompting techniques. Few-shot prompting is when you provide the LLM a few examples of the type of output or steps you are looking for, which helps to guide the LLM‚Äôs response. COT provides examples of reasoning steps and ReAct provides examples of thought, action, and observation steps. In both cases this allows the LLM to make a more informed response compared to simply prompting the model with an unstructured question. ---"
  },
  {
    "article_id": "91e1475718cbd3d6",
    "article_title": "üí° What is Prompt Engineering ?:: RAG, CoT, ReAct & DSP Explained",
    "article_url": "https://medium.com/@tahirbalarabe2/what-is-prompt-engineering-rag-cot-react-dsp-explained-0aa0a9bd0a90",
    "module": "02-core-techniques",
    "tags": [
      "prompt-engineering",
      "chain-of-thought",
      "RAG"
    ],
    "chunk_index": 4,
    "total_chunks": 5,
    "text": "examples of thought, action, and observation steps. In both cases this allows the LLM to make a more informed response compared to simply prompting the model with an unstructured question. ---"
  }
]