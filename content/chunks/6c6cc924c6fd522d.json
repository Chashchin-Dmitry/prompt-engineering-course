[
  {
    "article_id": "6c6cc924c6fd522d",
    "article_title": "The Skill That Multiplies Developer Productivity : Prompt Engineering",
    "article_url": "https://medium.com/@shoaibkhalid65/the-skill-that-multiplies-developer-productivity-prompt-engineering-0255ebfcc0a1",
    "module": "03-advanced",
    "tags": [
      "prompt-engineering",
      "RAG",
      "developer"
    ],
    "chunk_index": 0,
    "total_chunks": 6,
    "text": "The Skill That Multiplies Developer Productivity : Prompt Engineering Muhammad Shoaib Khalid 10 min read Â· 2 days ago -- Press enter or click to view image in full size AI Generated Image AI can already write code, generate content, and analyze data. Most developers fail to get the results they want â€” not because AI is weak, but because their prompts are vague. Most developers know syntax; few understand intent. The difference? The ability to guide AI with precision â€” and that skill is now gold. Most developers use AI daily, but the outputs are often generic or low-value. The real skill gap isnâ€™t in coding anymore â€” itâ€™s in clarity of thought and communication. Vague prompts = wasted time and poor results. Clear prompts = high productivity, better outputs, and faster prototyping. Typing â€œWrite a blog about productivityâ€ produces generic output. Typing a detailed, context-rich prompt can generate a ready-to-publish article in minutes. What is Prompt Engineering? Prompt engineering may sound like a fancy and complicated term, but in reality, itâ€™s neither difficult nor a type of traditional engineering. The word â€œpromptâ€ has different meanings depending on the context: In literature, it means to encourage or inspire . In computer science, it refers to a piece of text, symbol, or message displayed by a system, indicating it is ready to receive input or execute a command . In the context of AI, prompt engineering is the skill of writing prompts in a way that guides your generative AI tool to produce the output you want , efficiently and accurately. The â€œT.C.R.E.I.â€ Framework To get the best results from generative AI, Google recommends a five-step framework called T.C.R.E.I , designed to help you create clear, effective, and high-quality prompts. The mnemonic makes it easier to remember: ğ—§ğ—µğ—¼ğ˜‚ğ—´ğ—µğ˜ğ—³ğ˜‚ğ—¹ğ—¹ğ˜† ğ—–ğ—¿ğ—²ğ—®ğ˜ğ—² ğ—¥ğ—²ğ—®ğ—¹ğ—¹ğ˜† ğ—˜ğ˜…ğ—°ğ—²ğ—¹ğ—¹ğ—²ğ—»ğ˜ ğ—œğ—»ğ—½ğ˜‚ğ˜ğ˜€ 1ï¸âƒ£ Task What it is: Describe the task you want the AI tool to perform. Why it matters: A vague task produces vague results. The AI needs clear instructions . Key elements: Persona: Specify the expertise the AI should draw from. For example: â€œAct as a senior Android developer with 5 years of experience.â€ Format: Define how you want the output. For example: â€œProvide a 300-word tutorial in step-by-step format.â€ Example: Task: Write a marketing email promoting a new app, as if you are a copywriter specializing in mobile tech products. Use a friendly and persuasive tone, with 3 bullet points highlighting key features. 2ï¸âƒ£ Context What it is: Provide necessary background information so the AI understands your situation. Why it matters: Context helps the AI produce relevant and accurate outputs. Example: Context: The app is designed for opticians to manage inventory, track sales, and schedule appointments. Target audience: opticians aged 25â€“40 who are tech-savvy but busy. 3ï¸âƒ£ References What it is: Include examples, prior work, or relevant resources. These can be text, images, or files. Why it matters: References give the AI a concrete idea of your desired output quality and style. Example: References: Include previous marketing"
  },
  {
    "article_id": "6c6cc924c6fd522d",
    "article_title": "The Skill That Multiplies Developer Productivity : Prompt Engineering",
    "article_url": "https://medium.com/@shoaibkhalid65/the-skill-that-multiplies-developer-productivity-prompt-engineering-0255ebfcc0a1",
    "module": "03-advanced",
    "tags": [
      "prompt-engineering",
      "RAG",
      "developer"
    ],
    "chunk_index": 1,
    "total_chunks": 6,
    "text": "audience: opticians aged 25â€“40 who are tech-savvy but busy. 3ï¸âƒ£ References What it is: Include examples, prior work, or relevant resources. These can be text, images, or files. Why it matters: References give the AI a concrete idea of your desired output quality and style. Example: References: Include previous marketing emails from the company or a similar app. Attach screenshots of the app interface to highlight features. 4ï¸âƒ£ Evaluate What it is: Assess the AI-generated output to see if it meets your expectations. Why it matters: Not every prompt will produce perfect results the first time. Evaluation ensures quality. How to do it: Check if the output fulfills the task requirements. Assess tone, style, accuracy, and relevance. Decide whether further refinement is needed. 5ï¸âƒ£ Iterate What it is: Refine and repeat the prompting process until the output meets your needs. Why it matters: Iteration allows you to improve clarity, add missing details, and optimize output quality . Generate better outputs through Iteration: Revisit the prompting framework Break the prompt into shorter sentences Tweak your phrasing or switch to a analogous task Introduce the clear constraints Its very important step, actually its the way of improving the prompt continuously. MultiModal Prompting Modalities Modalities are the different formats in which generative AI tools can receive or produce information . This can include text, images, audio, or even video inputs and outputs. What is Multimodal Prompting? Multimodal prompting involves using multiple modalities at the same time to guide the AI. For example: While generating an image, you can provide a reference image and simultaneously give text instructions describing modifications or context. This allows the AI to produce outputs that are more precise, context-aware, and aligned with your vision . Responsible while using AI When using generative AI tools, itâ€™s important to use them responsibly : Follow organizational policies â€” Always adhere to your companyâ€™s guidelines regarding AI usage. Avoid sensitive or personal data â€” Never input confidential, private, or personally identifiable information into AI tools. Verify AI outputs â€” AI-generated content can contain hallucinations, inconsistencies, or errors . Always double-check the results before using them. ğŸ’¡ Tip: Treat AI outputs as assistive suggestions , not final authority. Human oversight is essential to ensure accuracy and reliability. How Generative AI Handles the Tone and Style Ever noticed how some AI-generated content can feel robotic , while other times it feels like youâ€™re chatting with a friend or a professor ? The reason lies in how generative AI tools handle tone and style . Contextual Understanding Think of a Generative AI tool are trained on massive datasets of everyday conversations. For example, if you ask: â€œWhatâ€™s up?â€ The AI recognizes this common greeting and responds appropriately, e.g.: â€œNot much, how about you?â€ This ability comes from contextual understanding , allowing AI to interpret input based on patterns it has learned. Strategies for Tone and Style in Prompting When it comes to matching tone and style, a gen AI tools contextual understanding is a key ingredient."
  },
  {
    "article_id": "6c6cc924c6fd522d",
    "article_title": "The Skill That Multiplies Developer Productivity : Prompt Engineering",
    "article_url": "https://medium.com/@shoaibkhalid65/the-skill-that-multiplies-developer-productivity-prompt-engineering-0255ebfcc0a1",
    "module": "03-advanced",
    "tags": [
      "prompt-engineering",
      "RAG",
      "developer"
    ],
    "chunk_index": 2,
    "total_chunks": 6,
    "text": "appropriately, e.g.: â€œNot much, how about you?â€ This ability comes from contextual understanding , allowing AI to interpret input based on patterns it has learned. Strategies for Tone and Style in Prompting When it comes to matching tone and style, a gen AI tools contextual understanding is a key ingredient. but it does not make the whole recipe. that where you come in .Here are few ways to adjust your prompts to help fine-tune the tone and style Hereâ€™s how: Specify your tone and style when using the prompting framework enter your desired tone and style with in the task. For Example: Basic prompt: â€œSummarize this report into three short paragraphs.â€ Refined prompt: â€œSummarize this report into three short paragraphs in a friendly, professional, and easy-to-comprehend tone.â€ Bottom line: Donâ€™t leave things to interpretation. The more specific you are about the tone you want, the better the tool can match your expectations. 2. Provide tone and style references You can specify your tone and style even further by providing a reference for the generative AI tool to work from. 3. Iterate on tone and style If your initial output does not feel quite right, thatâ€™s a good time to get more specific by iterating on your prompt and adding more details and directions. Why Prompting for Tone and Style Matters Whether you are crafting a professional email , a fun social media post , or a persuasive essay , the right tone and style can make all the difference in how your message is communicated and received. Advanced Summarization Techniques Generative AI tools can help significantly in summarizing lengthy documents according to your prompt. You can also provide a format or persona , and moreover, a generative AI tool can generate new content based on long previous content. Why Basic Summaries Arenâ€™t Enough When you ask a generative AI tool to provide a summary, sometimes the initial output is too broad . You may need more detail to make it truly useful. A technique called Chain of Density can help with that. With this method, you get increasingly concise summaries and end up with a chain of refined outputs. Think of it this way: you are working on the perfect elevator pitch for your company. Your first draft is too long and includes too many details. As you refine it, it becomes shorter and more direct â€” without losing the important points you need to communicate. Chain of Density Chain of Density is a smart way to summarize long content step by step so the result becomes compact, information-rich, and easy to understand . Instead of creating one short summary immediately, it gradually improves the summary by adding important details while keeping the length nearly the same. How it works (Iterative Summarization): Start with a simple, short summary. Identify missing important details. Rewrite the summary by packing more key information into the same length. Repeat until the summary is dense but still readable. Think of it like compressing a file:"
  },
  {
    "article_id": "6c6cc924c6fd522d",
    "article_title": "The Skill That Multiplies Developer Productivity : Prompt Engineering",
    "article_url": "https://medium.com/@shoaibkhalid65/the-skill-that-multiplies-developer-productivity-prompt-engineering-0255ebfcc0a1",
    "module": "03-advanced",
    "tags": [
      "prompt-engineering",
      "RAG",
      "developer"
    ],
    "chunk_index": 3,
    "total_chunks": 6,
    "text": "while keeping the length nearly the same. How it works (Iterative Summarization): Start with a simple, short summary. Identify missing important details. Rewrite the summary by packing more key information into the same length. Repeat until the summary is dense but still readable. Think of it like compressing a file: First version â†’ basic overview Next versions â†’ more meaningful details added Final version â†’ concise + complete Summarization Best Practices 1. Write a Strong Prompt Generative AI tools use pattern recognition to analyze text and refine it into shorter summaries. To ensure your summary contains the right information and is in the correct format and depth, create a strong prompt specifying exactly what you need. Include: desired length format (bullet points, paragraphs, etc.) audience level key focus areas 2. AI Models and Token Limits Tokens are the fundamental building blocks of text that AI models use to process and understand language. A token can be a single character, part of a word, or multiple words. When you give a generative AI tool a prompt, it breaks it down into tokens. The longer the prompt, the more tokens are required to generate an output. Earlier AI models could process only several thousand tokens at once, but modern models can process hundreds of thousands or even millions . Long Context Windows A long context window refers to the amount of text an AI model can consider at one time while generating a response. This is especially important when summarizing large documents such as: research papers technical documentation meeting transcripts books or reports With long context windows, AI can: maintain coherence across large inputs retain important details generate more accurate and complete summaries reduce the need to split content into smaller parts In simple terms: A larger context window allows the AI to â€œsee the bigger pictureâ€ before summarizing. Bottom Line Advanced summarization techniques help transform lengthy content into concise, meaningful insights. Using methods like Chain of Density , writing strong prompts, and leveraging long context windows ensures summaries that are: âœ” concise âœ” information-rich âœ” accurate âœ” easy to understand Prompt Chaining Think of it like a jigsaw puzzle: you donâ€™t just dump the pieces and hope for a picture â€” you build it deliberately, piece by piece. Prompt chaining is the process of using the output of one prompt as the building block for the next. 1. Chaining vs. Iterating It is important to understand the difference: Iteration Rewording or refining the same prompt to get a better version of the same result . Chaining Taking the AIâ€™s successful answer and asking it to do something new or more complex based on that answer. 2. Why It Works Context Building Each step adds a new layer of detail. Complexity Management It breaks one massive, â€œimpossibleâ€ task into smaller, manageable steps. Memory & Continuity Tools like Gemini have a long context window, meaning they remember the previous parts of the chain so you donâ€™t have to repeat yourself. 3. Key Takeaway"
  },
  {
    "article_id": "6c6cc924c6fd522d",
    "article_title": "The Skill That Multiplies Developer Productivity : Prompt Engineering",
    "article_url": "https://medium.com/@shoaibkhalid65/the-skill-that-multiplies-developer-productivity-prompt-engineering-0255ebfcc0a1",
    "module": "03-advanced",
    "tags": [
      "prompt-engineering",
      "RAG",
      "developer"
    ],
    "chunk_index": 4,
    "total_chunks": 6,
    "text": "Each step adds a new layer of detail. Complexity Management It breaks one massive, â€œimpossibleâ€ task into smaller, manageable steps. Memory & Continuity Tools like Gemini have a long context window, meaning they remember the previous parts of the chain so you donâ€™t have to repeat yourself. 3. Key Takeaway If Product is complex or large donâ€™t ask for the final product all at once. Guide the AI through a sequence where each response serves as the foundation for the next task. Advanced Prompting: How AI â€œThinksâ€ While standard chaining builds a sequence, these techniques help the AI solve tougher problems by showing its work. 1. Chain of Thought (CoT) The Concept: Asking the AI to show its work. The Analogy: Itâ€™s like a math teacher saying, â€œDonâ€™t just give me the answer; show me the steps you took to get there.â€ How to do it: Include phrases like: â€œExplain your reasoning step by step.â€ â€œWalk me through your thought process.â€ Why itâ€™s useful: It helps you spot errors in the AIâ€™s logic. It helps you make better decisions because you understand why the suggestion was made. (Example: Why did it pick these 3 cities for the book tour instead of others?) 2. Tree of Thought (ToT) The Concept: Asking the AI to explore multiple paths or â€œbranchesâ€ at the same time. The Analogy: Itâ€™s like a maze or a tree. Instead of moving in just one direction, the AI explores several paths, checks which ones fail, and follows the one that leads to the best result. How to do it: Ask the AI to: â€œExplore three different ways to solve this.â€ â€œEvaluate the pros and cons of each option.â€ Why itâ€™s useful: Perfect for creative or abstract problems (e.g., brainstorming different plot twists for a sequel). Helps find the best outcome by comparing ideas side by side before choosing one. Summary Tip Chain of Thought gives you depth (one deep explanation), while Tree of Thought gives you breadth (many different options). Meta-Prompting: The â€œPrompt Designerâ€ Meta-prompting (also called Automatic Prompt Engineering ) is when you use AI to help you write, fix, or improve your prompts. Instead of guessing what to ask, you ask the AI: â€œHow should I ask you for this?â€ 1. Prompt Generation (Creating from Scratch) When you donâ€™t know where to start, use these strategies: Direct Generation Simply ask the AI to write a prompt for a specific task. Example: â€œWrite a prompt for a job offer letter.â€ Template Request Ask for an outline of the most important elements your prompt should include. Reference-Based (Image/Text) Upload a file or image and ask: â€œBased on this, generate a prompt that captures this exact style/information.â€ Meta-Prompt Chaining Break a big prompt into smaller pieces. Example: First ask for a prompt that defines a good tone Then use that to build your full request 2. Prompt Refinement (Fixing What You Have) When your current prompt isnâ€™t working well, use these power-up strategies : Leveling Up What it does:"
  },
  {
    "article_id": "6c6cc924c6fd522d",
    "article_title": "The Skill That Multiplies Developer Productivity : Prompt Engineering",
    "article_url": "https://medium.com/@shoaibkhalid65/the-skill-that-multiplies-developer-productivity-prompt-engineering-0255ebfcc0a1",
    "module": "03-advanced",
    "tags": [
      "prompt-engineering",
      "RAG",
      "developer"
    ],
    "chunk_index": 5,
    "total_chunks": 6,
    "text": "Break a big prompt into smaller pieces. Example: First ask for a prompt that defines a good tone Then use that to build your full request 2. Prompt Refinement (Fixing What You Have) When your current prompt isnâ€™t working well, use these power-up strategies : Leveling Up What it does: Makes a boring prompt more engaging. Example: â€œHow can I change this prompt to sound more exciting?â€ Remixing What it does: Combines multiple prompts into one stronger version. Example: â€œCombine these three drafts into one perfect instruction.â€ Style Swap What it does: Changes the mood or tone of a prompt. Example: â€œRewrite this technical prompt to focus on emotion and passion.â€ The Golden Rule If you are struggling to get the right answer, stop trying to fix the answer â€” start asking the AI to fix the prompt. Note: The concepts discussed in this article are based on insights from the Google Prompting Essentials course. If youâ€™re interested in learning more, you can explore the course here: course link . If you found this article helpful, consider giving it a clap ğŸ‘. ---"
  }
]