{
  "id": "91e1475718cbd3d6",
  "title": "üí° What is Prompt Engineering ?:: RAG, CoT, ReAct & DSP Explained",
  "source": "medium",
  "url": "https://medium.com/@tahirbalarabe2/what-is-prompt-engineering-rag-cot-react-dsp-explained-0aa0a9bd0a90",
  "author": "Tahir",
  "published": "None",
  "scraped": "2026-02-20",
  "tags": [
    "prompt-engineering",
    "chain-of-thought",
    "RAG"
  ],
  "module": "02-core-techniques",
  "word_count": 1831,
  "content": "üí° What is Prompt Engineering ?:: RAG, CoT, ReAct & DSP Explained\nTahir\n7 min read\n¬∑\nJan 31, 2025\n--\nIf you‚Äôve spent any time on LinkedIn lately, you‚Äôve probably seen job postings for ‚Äúprompt engineers.‚Äù A few years ago, this job didn‚Äôt exist. Now, companies are scrambling to hire people who know how to ask AI the right questions.\nThe reason is simple: large language models (LLMs) don‚Äôt just think on their own. They generate text based on probabilities, and if you don‚Äôt guide them well, they‚Äôll make things up. AI researchers call these mistakes ‚Äúhallucinations,‚Äù but it‚Äôs really just bad prompting. The solution? Better prompts.\nThere are four main techniques for doing this: Retrieval-Augmented Generation (RAG), Chain of Thought (CoT), ReAct, and Directional Stimulus Prompting (DSP). Each solves a different problem, and when used together, they make AI far more reliable.\nRetrieval-Augmented Generation (RAG)\nMost AI models are trained on internet data. This means they don‚Äôt know anything about your company‚Äôs internal policies or the latest financial reports. If you ask an LLM about your revenue last year, it won‚Äôt know. It will guess.\nRAG fixes this. Instead of relying purely on the model‚Äôs training data, you first retrieve relevant information from a trusted source ‚Äî like a company database or a document repository ‚Äî and then feed it into the model. Now, when you ask about revenue, the model isn‚Äôt pulling numbers from the air. It‚Äôs using real data.\nThis works best when paired with vector databases, which store text in a format that AI can quickly search. If you‚Äôve ever used a chatbot that seems to ‚Äúknow‚Äù your company‚Äôs policies, it‚Äôs probably using RAG.\nChain of Thought (CoT)\nMost people assume AI works like a calculator ‚Äî give it an input, and it instantly spits out the right answer. But LLMs don‚Äôt work that way. They generate text one token at a time, based on what‚Äôs most likely to come next.\nThis can cause problems when answering complex questions. If you ask, ‚ÄúWhat was our total revenue for 2022?‚Äù the model might throw out a number with no reasoning. Chain of Thought prompting forces the model to show its work.\nInstead of asking for a single number, you break the problem into parts:\nWhat was the revenue from software sales?\nWhat was the revenue from consulting?\nWhat was the revenue from hardware?\nNow, sum them up.\nBy structuring the question this way, you help the model arrive at a more reliable answer. And even if it‚Äôs wrong, you can see where it went wrong.\nReAct\nRAG brings in external data. Chain of Thought forces reasoning. But what if the model needs information that isn‚Äôt in its training data or your private knowledge base?\nThis is where ReAct comes in. It lets AI decide when to retrieve more data before answering.\nImagine you ask, ‚ÄúWhat were our revenues in 2010 and 2022?‚Äù The model might find 2022‚Äôs numbers in your database but not 2010‚Äôs. Instead of making up a number, it can recognize the gap, search an external source, and then combine both numbers before responding.\nReAct is useful when models need to cross-check information from multiple places. It prevents AI from answering when it shouldn‚Äôt and makes sure responses are built on actual data.\nDirectional Stimulus Prompting (DSP)\nSometimes you don‚Äôt want a general answer. You want AI to focus on specific details. That‚Äôs where DSP comes in.\nSuppose you ask, ‚ÄúWhat were our total earnings last year?‚Äù The model might give you one number. But if you want more precision, you can direct it:\n‚ÄúFocus on software and consulting revenue.‚Äù\n‚ÄúIgnore international sales.‚Äù\n‚ÄúSummarize in three bullet points.‚Äù\nThis kind of prompting works like giving hints in a guessing game. Instead of asking for a broad answer, you nudge the model toward what you actually need. It‚Äôs simple but surprisingly effective.\nCombining These Techniques\nThe real power of prompt engineering comes from combining these techniques. For example, you might start with RAG to ground the model in your domain knowledge, then use COT to break down a complex problem, and finally apply DSP to extract specific details. Each technique has its strengths, and using them together can produce results that are far more accurate and insightful than any single approach.\nEach of these techniques solves a different problem:\nRAG makes sure AI has access to the right data.\nChain of Thought forces reasoning.\nReAct lets AI search for missing info.\nDSP helps you steer the response.\nUsed together, they make AI much more reliable. Instead of answering based on random training data, the model retrieves real facts, reasons through them, pulls in extra information if needed, and presents the result in the right format.\nThis is what good prompt engineering looks like. It‚Äôs not about tricking AI into giving better answers. It‚Äôs about structuring your questions so the model works the way you want.\nIf you want AI to be useful, don‚Äôt just ask it questions. Guide it.\nWhy This Matters\nPrompt engineering isn‚Äôt just a technical skill; it‚Äôs a way of thinking. It forces you to clarify your questions and understand the limitations of the tools you‚Äôre using. And like any form of communication, it‚Äôs iterative. You rarely get the perfect response on the first try. You refine your prompts, test different approaches, and learn from the results.\nThis is why prompt engineering is becoming such a sought-after skill. As LLMs become more integrated into our workflows, the ability to communicate effectively with them will be as important as knowing how to use a spreadsheet or write code. It‚Äôs not just about making the models work ‚Äî it‚Äôs about making them work\nfor you\n.\nSo if you‚Äôre curious about this field, start experimenting. Play around with different prompts. Try combining techniques. And remember: the best way to learn prompt engineering is by doing it. The more you practice, the better you‚Äôll get. And who knows? You might just find yourself becoming one of those in-demand prompt engineers.\nFurther Reading::\nü§ñChatGPT for Vulnerability Detection by Tahir Balarabe\nWhat are AI Agents?\nStable Diffusion Deepfakes: Creation and Detection\nThe Difference Between AI Assistants and AI Agents (And Why It Matters)\nüöÄDeepSeek R1 Explained: Chain of Thought, Reinforcement Learning, and Model Distillation\nü§îWhat is AI Inferencing?\nüí°Prompt Tuning: A New Approach to Large Language Model Specialization\nüí°Retrieval-Augmented Generation(RAG) for Accurate LLMs\nFAQ on Prompt Engineering Techniques\nWhat is prompt engineering and why is it important?\nPrompt engineering is the practice of designing effective questions and instructions (prompts) to elicit desired responses from large language models (LLMs). It‚Äôs crucial because LLMs are trained on vast datasets and can produce inaccurate or nonsensical outputs (hallucinations) if not guided properly. By carefully crafting prompts, we can minimize these issues and leverage the LLMs capabilities effectively for specific tasks.\nWhat is Retrieval Augmented Generation (RAG) and how does it improve LLM responses?\nRAG enhances LLMs by incorporating domain-specific knowledge into the process. LLMs are not inherently aware of private or niche knowledge bases. RAG works by first retrieving relevant information from your specific knowledge source (e.g., a company database) using a retrieval component. Then this retrieved context is combined with your question to provide LLM a foundation for its answer. This allows the model to provide answers based on your domain specific data, improving accuracy and relevance over using the LLM‚Äôs generic training.\nHow does the Chain-of-Thought (COT) prompting technique work and how does it differ from RAG?\nCOT is a method that guides the LLM through a problem by breaking it down into multiple steps. Rather than asking a complex question directly, you prompt the model to reason through each part of the question, and then combine these into a final result. For example, instead of asking for the total earnings of a company, you might ask for earnings by software, hardware, and consulting before adding them together. This encourages explainability and often leads to more accurate results. COT is a technique that\nbuilds\non the base accuracy of results (such as ones achieved through the RAG technique) by providing a framework for better question phrasing, whereas RAG is a method to improve the model‚Äôs content awareness.\nWhat is the ReAct prompting technique, and how does it differ from both RAG and COT?\nReAct combines reasoning (similar to COT) with the ability to take\nactions\nby accessing external resources. If the answer cannot be found entirely in the internal or domain-specific knowledge base, ReAct prompts the LLM to search for information in external public sources as well. This means the model can gather missing data from various sources to complete the task. For instance, in the example of retrieving financial data for two different years, ReAct is able to retrieve one from a private database and then supplement it with one from a public source. ReAct uses a 3 step process of ‚Äúthought,‚Äù ‚Äúaction,‚Äù and ‚Äúobservation‚Äù to accomplish this.\nCan you explain Directional Stimulus Prompting (DSP) and its usefulness?\nDSP is a technique to guide the model towards very specific information from within a result. When asking a question, you include specific keywords or ‚Äúhints‚Äù to encourage the model to extract particular data from a larger result. For example, you may ask, ‚ÄúWhat is the company‚Äôs annual earnings, specifically for the software and consulting departments?‚Äù It‚Äôs a simple yet effective method for extracting specific pieces of information.\nHow are these different prompt engineering techniques combined for optimal results?\nA common approach is to start with RAG to ground the LLM in your domain specific knowledge. You can then layer in other techniques, such as combining Chain-of-Thought with RAG, or even ReAct with RAG. For very specific data extraction, the combination of RAG and DSP can be highly effective. The goal is to leverage the cumulative effect of these techniques to refine the LLM‚Äôs response.\nWhat are ‚Äúhallucinations‚Äù in the context of large language models, and how do these techniques address them?\n‚ÄúHallucinations‚Äù in LLMs refer to inaccurate or false outputs generated by the model. These occur when the model relies too heavily on its pre-training data or makes up information because it lacks awareness of a context. Techniques like RAG address this by grounding responses in domain-specific knowledge, while methods like COT and ReAct encourage logical reasoning by the LLM and use of external sources. DSP also plays a role by guiding the model to more targeted answers.\nWhat are the ‚Äúfew-shot‚Äù prompting techniques that were discussed in the source?\nBoth Chain-of-Thought (COT) and ReAct are considered few-shot prompting techniques. Few-shot prompting is when you provide the LLM a few examples of the type of output or steps you are looking for, which helps to guide the LLM‚Äôs response. COT provides examples of reasoning steps and ReAct provides examples of thought, action, and observation steps. In both cases this allows the LLM to make a more informed response compared to simply prompting the model with an unstructured question.\n\n---",
  "summary": "–û–±–∑–æ—Ä 4 –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ö–Ω–∏–∫ –ø—Ä–æ–º—Ç–∏–Ω–≥–∞: RAG (–¥–æ–±–∞–≤–ª—è–µ—Ç –≤–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ), Chain of Thought (–∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ), ReAct (–ø–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏), DSP (–Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ—Ç–∞–ª–∏). –û–±—ä—è—Å–Ω—è–µ—Ç –∫–∞–∫ –∏ –∫–æ–≥–¥–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –∏—Ö.",
  "summary_en": "Overview of 4 core prompting techniques: RAG (grounds model in external data), Chain of Thought (forces step-by-step reasoning), ReAct (real-time data retrieval), DSP (directs model to specific details). Explains when and how to combine them.",
  "key_insights": [
    "–ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ ‚Äî —ç—Ç–æ –Ω–µ –±–∞–≥ –º–æ–¥–µ–ª–∏, —ç—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–ª–æ—Ö–æ–≥–æ –ø—Ä–æ–º—Ç–∏–Ω–≥–∞",
    "RAG: –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ + –∑–∞–ø—Ä–æ—Å ‚Üí –º–æ–¥–µ–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–µ—Ç",
    "CoT: —Ä–∞–∑–±–∏–≤–∞–π —Å–ª–æ–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å –Ω–∞ —à–∞–≥–∏, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –≥–¥–µ –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è",
    "ReAct: –º–æ–¥–µ–ª—å –°–ê–ú–ê —Ä–µ—à–∞–µ—Ç –∫–æ–≥–¥–∞ –Ω—É–∂–µ–Ω –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫",
    "DSP: –¥–æ–±–∞–≤–ª—è–π —Ö–∏–Ω—Ç—ã ('—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ X', '–∏–≥–Ω–æ—Ä–∏—Ä—É–π Y') –¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤",
    "–ö–æ–º–±–∏–Ω–∞—Ü–∏—è: RAG ‚Üí CoT ‚Üí DSP = –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å"
  ],
  "practical_example": "–í–º–µ—Å—Ç–æ 'What was our revenue?' ‚Üí RAG –¥–æ—Å—Ç–∞—ë—Ç –¥–∞–Ω–Ω—ã–µ, CoT —Ä–∞–∑–±–∏–≤–∞–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º, DSP —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç –Ω–∞ –Ω—É–∂–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ",
  "course_relevance": "–ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –º–æ–¥—É–ª—è 02 ‚Äî –±–∞–∑–æ–≤—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏. –•–æ—Ä–æ—à–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤.",
  "quality_score": 8,
  "difficulty": "beginner"
}