{
  "id": "6c6cc924c6fd522d",
  "title": "The Skill That Multiplies Developer Productivity : Prompt Engineering",
  "source": "medium",
  "url": "https://medium.com/@shoaibkhalid65/the-skill-that-multiplies-developer-productivity-prompt-engineering-0255ebfcc0a1",
  "author": "Muhammad Shoaib Khalid",
  "published": "None",
  "scraped": "2026-02-20",
  "tags": [
    "prompt-engineering",
    "RAG",
    "developer"
  ],
  "module": "03-advanced",
  "word_count": 2433,
  "content": "The Skill That Multiplies Developer Productivity : Prompt Engineering\nMuhammad Shoaib Khalid\n10 min read\nÂ·\n2 days ago\n--\nPress enter or click to view image in full size\nAI Generated Image\nAI can already write code, generate content, and analyze data. Most developers fail to get the results they want â€” not because AI is weak, but because their prompts are vague.\nMost developers know syntax; few understand intent. The difference? The ability to guide AI with precision â€” and that skill is now gold.\nMost developers use AI daily, but the outputs are often generic or low-value.\nThe real skill gap isnâ€™t in coding anymore â€” itâ€™s in clarity of thought and communication.\nVague prompts = wasted time and poor results.\nClear prompts = high productivity, better outputs, and faster prototyping.\nTyping â€œWrite a blog about productivityâ€ produces generic output.\nTyping a detailed, context-rich prompt can generate a ready-to-publish article in minutes.\nWhat is Prompt Engineering?\nPrompt engineering may sound like a fancy and complicated term, but in reality, itâ€™s neither difficult nor a type of traditional engineering.\nThe word\nâ€œpromptâ€\nhas different meanings depending on the context:\nIn literature, it means\nto encourage or inspire\n.\nIn computer science, it refers to\na piece of text, symbol, or message displayed by a system, indicating it is ready to receive input or execute a command\n.\nIn the context of AI,\nprompt engineering\nis the skill of writing prompts in a way that guides your generative AI tool to produce the\noutput you want\n, efficiently and accurately.\nThe â€œT.C.R.E.I.â€ Framework\nTo get the best results from generative AI, Google recommends a\nfive-step framework\ncalled\nT.C.R.E.I\n, designed to help you create clear, effective, and high-quality prompts. The mnemonic makes it easier to remember:\nğ—§ğ—µğ—¼ğ˜‚ğ—´ğ—µğ˜ğ—³ğ˜‚ğ—¹ğ—¹ğ˜† ğ—–ğ—¿ğ—²ğ—®ğ˜ğ—² ğ—¥ğ—²ğ—®ğ—¹ğ—¹ğ˜† ğ—˜ğ˜…ğ—°ğ—²ğ—¹ğ—¹ğ—²ğ—»ğ˜ ğ—œğ—»ğ—½ğ˜‚ğ˜ğ˜€\n1ï¸âƒ£ Task\nWhat it is:\nDescribe the task you want the AI tool to perform.\nWhy it matters:\nA vague task produces vague results. The AI needs\nclear instructions\n.\nKey elements:\nPersona:\nSpecify the expertise the AI should draw from. For example:\nâ€œAct as a senior Android developer with 5 years of experience.â€\nFormat:\nDefine how you want the output. For example:\nâ€œProvide a 300-word tutorial in step-by-step format.â€\nExample:\nTask: Write a marketing email promoting a new app, as if you are a copywriter specializing in mobile tech products. Use a friendly and persuasive tone, with 3 bullet points highlighting key features.\n2ï¸âƒ£ Context\nWhat it is:\nProvide necessary background information so the AI understands your situation.\nWhy it matters:\nContext helps the AI produce relevant and accurate outputs.\nExample:\nContext: The app is designed for opticians to manage inventory, track sales, and schedule appointments. Target audience: opticians aged 25â€“40 who are tech-savvy but busy.\n3ï¸âƒ£ References\nWhat it is:\nInclude examples, prior work, or relevant resources. These can be text, images, or files.\nWhy it matters:\nReferences give the AI a concrete idea of your desired output quality and style.\nExample:\nReferences: Include previous marketing emails from the company or a similar app. Attach screenshots of the app interface to highlight features.\n4ï¸âƒ£ Evaluate\nWhat it is:\nAssess the AI-generated output to see if it meets your expectations.\nWhy it matters:\nNot every prompt will produce perfect results the first time. Evaluation ensures quality.\nHow to do it:\nCheck if the output fulfills the task requirements.\nAssess tone, style, accuracy, and relevance.\nDecide whether further refinement is needed.\n5ï¸âƒ£ Iterate\nWhat it is:\nRefine and repeat the prompting process until the output meets your needs.\nWhy it matters:\nIteration allows you to\nimprove clarity, add missing details, and optimize output quality\n.\nGenerate better outputs through Iteration:\nRevisit the prompting framework\nBreak the prompt into shorter sentences\nTweak your phrasing or switch to a analogous task\nIntroduce the clear constraints\nIts very important step, actually its the way of improving the prompt continuously.\nMultiModal Prompting\nModalities\nModalities are the different\nformats in which generative AI tools can receive or produce information\n. This can include text, images, audio, or even video inputs and outputs.\nWhat is Multimodal Prompting?\nMultimodal prompting involves using\nmultiple modalities at the same time\nto guide the AI. For example:\nWhile generating an image, you can provide a\nreference image\nand simultaneously give\ntext instructions\ndescribing modifications or context.\nThis allows the AI to produce outputs that are\nmore precise, context-aware, and aligned with your vision\n.\nResponsible while using AI\nWhen using generative AI tools, itâ€™s important to\nuse them responsibly\n:\nFollow organizational policies\nâ€” Always adhere to your companyâ€™s guidelines regarding AI usage.\nAvoid sensitive or personal data\nâ€” Never input confidential, private, or personally identifiable information into AI tools.\nVerify AI outputs\nâ€” AI-generated content can contain\nhallucinations, inconsistencies, or errors\n. Always double-check the results before using them.\nğŸ’¡\nTip:\nTreat AI outputs as\nassistive suggestions\n, not final authority. Human oversight is essential to ensure accuracy and reliability.\nHow Generative AI Handles the Tone and Style\nEver noticed how some AI-generated content can feel\nrobotic\n, while other times it feels like youâ€™re chatting with a\nfriend or a professor\n? The reason lies in how generative AI tools handle\ntone and style\n.\nContextual Understanding\nThink of a Generative AI tool are trained on massive datasets of everyday conversations.\nFor example, if you ask:\nâ€œWhatâ€™s up?â€\nThe AI recognizes this common greeting and responds appropriately, e.g.:\nâ€œNot much, how about you?â€\nThis ability comes from\ncontextual understanding\n, allowing AI to interpret input based on patterns it has learned.\nStrategies for Tone and Style in Prompting\nWhen it comes to matching tone and style, a gen AI tools contextual understanding is a key ingredient. but it does not make the whole recipe. that where you come in .Here are few ways to adjust your prompts to help fine-tune the tone and style Hereâ€™s how:\nSpecify your tone and style\nwhen using the prompting framework enter your desired tone and style with in the task.\nFor Example:\nBasic prompt:\nâ€œSummarize this report into three short paragraphs.â€\nRefined prompt:\nâ€œSummarize this report into three short paragraphs in a friendly, professional, and easy-to-comprehend tone.â€\nBottom line:\nDonâ€™t leave things to interpretation. The more specific you are about the tone you want, the better the tool can match your expectations.\n2. Provide tone and style references\nYou can specify your tone and style even further by providing a reference for the generative AI tool to work from.\n3. Iterate on tone and style\nIf your initial output does not feel quite right, thatâ€™s a good time to get more specific by iterating on your prompt and adding more details and directions.\nWhy Prompting for Tone and Style Matters\nWhether you are crafting a\nprofessional email\n, a\nfun social media post\n, or a\npersuasive essay\n, the right tone and style can make all the difference in how your message is communicated and received.\nAdvanced Summarization Techniques\nGenerative AI tools can help significantly in summarizing lengthy documents according to your prompt. You can also provide a\nformat or persona\n, and moreover, a generative AI tool can generate new content based on long previous content.\nWhy Basic Summaries Arenâ€™t Enough\nWhen you ask a generative AI tool to provide a summary, sometimes the initial output is\ntoo broad\n. You may need more detail to make it truly useful.\nA technique called\nChain of Density\ncan help with that.\nWith this method, you get increasingly concise summaries and end up with a chain of refined outputs.\nThink of it this way: you are working on the perfect elevator pitch for your company. Your first draft is too long and includes too many details. As you refine it, it becomes shorter and more direct â€” without losing the important points you need to communicate.\nChain of Density\nChain of Density is a smart way to summarize long content step by step so the result becomes\ncompact, information-rich, and easy to understand\n.\nInstead of creating one short summary immediately, it gradually improves the summary by adding important details while keeping the length nearly the same.\nHow it works (Iterative Summarization):\nStart with a simple, short summary.\nIdentify missing important details.\nRewrite the summary by packing more key information into the same length.\nRepeat until the summary is dense but still readable.\nThink of it like compressing a file:\nFirst version\nâ†’ basic overview\nNext versions\nâ†’ more meaningful details added\nFinal version\nâ†’ concise + complete\nSummarization Best Practices\n1. Write a Strong Prompt\nGenerative AI tools use pattern recognition to analyze text and refine it into shorter summaries. To ensure your summary contains the right information and is in the correct format and depth, create a strong prompt specifying exactly what you need.\nInclude:\ndesired length\nformat (bullet points, paragraphs, etc.)\naudience level\nkey focus areas\n2. AI Models and Token Limits\nTokens are the fundamental building blocks of text that AI models use to process and understand language.\nA token can be a single character, part of a word, or multiple words.\nWhen you give a generative AI tool a prompt, it breaks it down into tokens.\nThe longer the prompt, the more tokens are required to generate an output.\nEarlier AI models could process only several thousand tokens at once, but modern models can process\nhundreds of thousands or even millions\n.\nLong Context Windows\nA\nlong context window\nrefers to the amount of text an AI model can consider at one time while generating a response.\nThis is especially important when summarizing large documents such as:\nresearch papers\ntechnical documentation\nmeeting transcripts\nbooks or reports\nWith long context windows, AI can:\nmaintain coherence across large inputs\nretain important details\ngenerate more accurate and complete summaries\nreduce the need to split content into smaller parts\nIn simple terms:\nA larger context window allows the AI to â€œsee the bigger pictureâ€ before summarizing.\nBottom Line\nAdvanced summarization techniques help transform lengthy content into concise, meaningful insights.\nUsing methods like\nChain of Density\n, writing strong prompts, and leveraging\nlong context windows\nensures summaries that are:\nâœ” concise\nâœ” information-rich\nâœ” accurate\nâœ” easy to understand\nPrompt Chaining\nThink of it like a jigsaw puzzle: you donâ€™t just dump the pieces and hope for a picture â€” you build it deliberately, piece by piece. Prompt chaining is the process of using the output of one prompt as the building block for the next.\n1. Chaining vs. Iterating\nIt is important to understand the difference:\nIteration\nRewording or refining the same prompt to get a better version of the\nsame result\n.\nChaining\nTaking the AIâ€™s successful answer and asking it to do something new or more complex based on that answer.\n2. Why It Works\nContext Building\nEach step adds a new layer of detail.\nComplexity Management\nIt breaks one massive, â€œimpossibleâ€ task into smaller, manageable steps.\nMemory & Continuity\nTools like\nGemini\nhave a long context window, meaning they remember the previous parts of the chain so you donâ€™t have to repeat yourself.\n3. Key Takeaway\nIf Product is complex or large donâ€™t ask for the final product all at once. Guide the AI through a sequence where each response serves as the foundation for the next task.\nAdvanced Prompting: How AI â€œThinksâ€\nWhile standard chaining builds a sequence, these techniques help the AI solve tougher problems by showing its work.\n1. Chain of Thought (CoT)\nThe Concept:\nAsking the AI to\nshow its work.\nThe Analogy:\nItâ€™s like a math teacher saying,\nâ€œDonâ€™t just give me the answer; show me the steps you took to get there.â€\nHow to do it:\nInclude phrases like:\nâ€œExplain your reasoning step by step.â€\nâ€œWalk me through your thought process.â€\nWhy itâ€™s useful:\nIt helps you spot errors in the AIâ€™s logic.\nIt helps you make better decisions because you understand\nwhy\nthe suggestion was made.\n(Example: Why did it pick these 3 cities for the book tour instead of others?)\n2. Tree of Thought (ToT)\nThe Concept:\nAsking the AI to explore multiple paths or â€œbranchesâ€ at the same time.\nThe Analogy:\nItâ€™s like a maze or a tree. Instead of moving in just one direction, the AI explores several paths, checks which ones fail, and follows the one that leads to the best result.\nHow to do it:\nAsk the AI to:\nâ€œExplore three different ways to solve this.â€\nâ€œEvaluate the pros and cons of each option.â€\nWhy itâ€™s useful:\nPerfect for creative or abstract problems\n(e.g., brainstorming different plot twists for a sequel).\nHelps find the\nbest outcome\nby comparing ideas side by side before choosing one.\nSummary Tip\nChain of Thought\ngives you\ndepth\n(one deep explanation), while\nTree of Thought\ngives you\nbreadth\n(many different options).\nMeta-Prompting: The â€œPrompt Designerâ€\nMeta-prompting (also called\nAutomatic Prompt Engineering\n) is when you use AI to help you write, fix, or improve your prompts.\nInstead of guessing what to ask, you ask the AI:\nâ€œHow should I ask you for this?â€\n1. Prompt Generation (Creating from Scratch)\nWhen you donâ€™t know where to start, use these strategies:\nDirect Generation\nSimply ask the AI to write a prompt for a specific task.\nExample:\nâ€œWrite a prompt for a job offer letter.â€\nTemplate Request\nAsk for an outline of the most important elements your prompt should include.\nReference-Based (Image/Text)\nUpload a file or image and ask:\nâ€œBased on this, generate a prompt that captures this exact style/information.â€\nMeta-Prompt Chaining\nBreak a big prompt into smaller pieces.\nExample:\nFirst ask for a prompt that defines a\ngood tone\nThen use that to build your full request\n2. Prompt Refinement (Fixing What You Have)\nWhen your current prompt isnâ€™t working well, use these\npower-up strategies\n:\nLeveling Up\nWhat it does:\nMakes a boring prompt more engaging.\nExample:\nâ€œHow can I change this prompt to sound more exciting?â€\nRemixing\nWhat it does:\nCombines multiple prompts into one stronger version.\nExample:\nâ€œCombine these three drafts into one perfect instruction.â€\nStyle Swap\nWhat it does:\nChanges the mood or tone of a prompt.\nExample:\nâ€œRewrite this technical prompt to focus on emotion and passion.â€\nThe Golden Rule\nIf you are struggling to get the right answer,\nstop trying to fix the answer â€” start asking the AI to fix the prompt.\nNote:\nThe concepts discussed in this article are based on insights from the Google Prompting Essentials course.\nIf youâ€™re interested in learning more, you can explore the course here:\ncourse link\n.\nIf you found this article helpful, consider giving it a clap ğŸ‘.\n\n---"
}