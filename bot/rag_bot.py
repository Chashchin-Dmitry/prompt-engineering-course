#!/usr/bin/env python3
"""
RAG Bot â€” ÑƒÐ¼Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð¿Ð¾ Ð¿Ñ€Ð¾Ð¼Ñ‚-Ð¸Ð½Ð¶Ð¸Ð½Ð¸Ñ€Ð¸Ð½Ð³Ñƒ.
ÐžÑ‚Ð²ÐµÑ‡Ð°ÐµÑ‚ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¾Ð¿Ð¸Ñ€Ð°ÑÑÑŒ Ð½Ð° ÑÐ¾Ð±Ñ€Ð°Ð½Ð½Ñ‹Ðµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ Ð¸Ð· Medium.

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:
  python bot/rag_bot.py                    # Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ CLI
  python bot/rag_bot.py "Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ RAG?"   # Ð¾Ð´Ð¸Ð½Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ
"""

import os
import sys
import json
from pathlib import Path
from dotenv import load_dotenv

load_dotenv(Path(__file__).parent.parent / "scripts" / ".env")

REPO_PATH       = Path(os.getenv("REPO_PATH", Path(__file__).parent.parent))
EMBEDDINGS_DIR  = REPO_PATH / "embeddings"
SYSTEM_PROMPT   = Path(__file__).parent / "prompts" / "system.md"

OPENAI_API_KEY  = os.getenv("OPENAI_API_KEY", "")
ANTHROPIC_KEY   = os.getenv("ANTHROPIC_API_KEY", "")
LLM_MODE        = os.getenv("LLM_MODE", "claude")   # "claude" | "openai" | "ollama"
EMBED_MODE      = os.getenv("EMBED_MODE", "openai")  # "openai" | "ollama"
COLLECTION_NAME = "prompt-engineering-course"
TOP_K           = 5  # ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ‡Ð°Ð½ÐºÐ¾Ð² Ð±Ñ€Ð°Ñ‚ÑŒ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°


def load_system_prompt() -> str:
    if SYSTEM_PROMPT.exists():
        return SYSTEM_PROMPT.read_text()
    return """Ð¢Ñ‹ ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ Ð¿Ñ€Ð¾Ð¼Ñ‚-Ð¸Ð½Ð¶Ð¸Ð½Ð¸Ñ€Ð¸Ð½Ð³Ñƒ Ð¸ AI-Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼.
ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¾Ð¿Ð¸Ñ€Ð°ÑÑÑŒ Ð¢ÐžÐ›Ð¬ÐšÐž Ð½Ð° Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· ÑÑ‚Ð°Ñ‚ÐµÐ¹.
Ð’ÑÐµÐ³Ð´Ð° ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº (Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ Ð¸ URL).
Ð•ÑÐ»Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÑ‚ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ â€” Ñ‡ÐµÑÑ‚Ð½Ð¾ ÑÐºÐ°Ð¶Ð¸ Ð¾Ð± ÑÑ‚Ð¾Ð¼.
ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° ÑÐ·Ñ‹ÐºÐµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ° (Ñ€ÑƒÑÑÐºÐ¸Ð¹ Ð¸Ð»Ð¸ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹)."""


def get_collection():
    import chromadb
    client = chromadb.PersistentClient(path=str(EMBEDDINGS_DIR))
    return client.get_collection(COLLECTION_NAME)


def embed_query(text: str) -> list:
    if EMBED_MODE == "ollama":
        import requests
        resp = requests.post(
            "http://localhost:11434/api/embeddings",
            json={"model": "nomic-embed-text", "prompt": text}
        )
        return resp.json()["embedding"]
    else:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
        resp = client.embeddings.create(model="text-embedding-3-small", input=[text])
        return resp.data[0].embedding


def search(query: str, top_k=TOP_K) -> list:
    """Ð˜Ñ‰ÐµÐ¼ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ðµ Ñ‡Ð°Ð½ÐºÐ¸ Ð² ChromaDB."""
    collection = get_collection()
    query_embedding = embed_query(query)
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k,
        include=["documents", "metadatas", "distances"]
    )

    chunks = []
    for i, doc in enumerate(results["documents"][0]):
        meta = results["metadatas"][0][i]
        score = 1 - results["distances"][0][i]  # cosine similarity
        chunks.append({
            "text": doc,
            "title": meta.get("article_title", ""),
            "url": meta.get("article_url", ""),
            "module": meta.get("module", ""),
            "score": round(score, 3),
        })
    return chunks


def build_context(chunks: list) -> str:
    """Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ‡Ð°Ð½ÐºÐ¾Ð²."""
    parts = []
    seen_urls = set()
    for i, chunk in enumerate(chunks):
        url = chunk["url"]
        source_label = f"[{chunk['title']}]({url})" if url not in seen_urls else chunk["title"]
        seen_urls.add(url)
        parts.append(f"--- Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº {i+1}: {source_label} (Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ: {chunk['score']}) ---\n{chunk['text']}")
    return "\n\n".join(parts)


def ask_claude(question: str, context: str, system: str) -> str:
    import anthropic
    client = anthropic.Anthropic(api_key=ANTHROPIC_KEY)
    response = client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=2000,
        system=system,
        messages=[{
            "role": "user",
            "content": f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· ÑÑ‚Ð°Ñ‚ÐµÐ¹:\n\n{context}\n\n---\n\nÐ’Ð¾Ð¿Ñ€Ð¾Ñ: {question}"
        }]
    )
    return response.content[0].text


def ask_openai(question: str, context: str, system: str) -> str:
    from openai import OpenAI
    client = OpenAI(api_key=OPENAI_API_KEY)
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n\n{context}\n\n---\n\nÐ’Ð¾Ð¿Ñ€Ð¾Ñ: {question}"}
        ]
    )
    return response.choices[0].message.content


def ask_ollama(question: str, context: str, system: str) -> str:
    import requests
    resp = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": "llama3",
            "system": system,
            "prompt": f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n\n{context}\n\n---\n\nÐ’Ð¾Ð¿Ñ€Ð¾Ñ: {question}",
            "stream": False
        }
    )
    return resp.json()["response"]


def answer(question: str) -> str:
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ: Ð²Ð¾Ð¿Ñ€Ð¾Ñ â†’ Ð¾Ñ‚Ð²ÐµÑ‚ Ñ‡ÐµÑ€ÐµÐ· RAG."""
    print(f"\nðŸ” Ð˜Ñ‰Ñƒ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ðµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸...")
    chunks = search(question)

    if not chunks:
        return "âŒ Ð’ Ð±Ð°Ð·Ðµ Ð¿Ð¾ÐºÐ° Ð½ÐµÑ‚ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð¾Ð² Ð¿Ð¾ ÑÑ‚Ð¾Ð¹ Ñ‚ÐµÐ¼Ðµ. Ð”Ð¾Ð¶Ð´Ð¸ÑÑŒ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ñ†Ð¸ÐºÐ»Ð° ÑÐ±Ð¾Ñ€Ð°."

    print(f"ðŸ“š ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(chunks)} Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ñ… Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¾Ð²:")
    for c in chunks:
        print(f"   â€¢ [{c['score']}] {c['title'][:60]}")

    context = build_context(chunks)
    system = load_system_prompt()

    print(f"\nðŸ¤– Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¾Ñ‚Ð²ÐµÑ‚ ({LLM_MODE})...")
    if LLM_MODE == "claude":
        return ask_claude(question, context, system)
    elif LLM_MODE == "openai":
        return ask_openai(question, context, system)
    else:
        return ask_ollama(question, context, system)


def cli():
    """Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼."""
    print("ðŸ§  RAG-Ð±Ð¾Ñ‚ Ð¿Ð¾ ÐŸÑ€Ð¾Ð¼Ñ‚-Ð˜Ð½Ð¶Ð¸Ð½Ð¸Ñ€Ð¸Ð½Ð³Ñƒ")
    print("   Ð—Ð°Ð´Ð°Ð²Ð°Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ Ð¸Ð»Ð¸ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼.")
    print("   Ð’Ð²ÐµÐ´Ð¸ 'exit' Ð´Ð»Ñ Ð²Ñ‹Ñ…Ð¾Ð´Ð°.\n")

    while True:
        try:
            question = input("â“ Ð’Ð¾Ð¿Ñ€Ð¾Ñ: ").strip()
        except (KeyboardInterrupt, EOFError):
            print("\nðŸ‘‹ ÐŸÐ¾ÐºÐ°!")
            break

        if not question:
            continue
        if question.lower() in ("exit", "quit", "Ð²Ñ‹Ñ…Ð¾Ð´"):
            print("ðŸ‘‹ ÐŸÐ¾ÐºÐ°!")
            break

        result = answer(question)
        print(f"\nðŸ’¬ ÐžÑ‚Ð²ÐµÑ‚:\n{result}\n")
        print("â”€" * 60)


if __name__ == "__main__":
    if len(sys.argv) > 1:
        q = " ".join(sys.argv[1:])
        print(answer(q))
    else:
        cli()
